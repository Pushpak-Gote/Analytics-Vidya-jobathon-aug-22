{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-08-07T18:17:50.189558Z","iopub.execute_input":"2022-08-07T18:17:50.190331Z","iopub.status.idle":"2022-08-07T18:17:50.206869Z","shell.execute_reply.started":"2022-08-07T18:17:50.190235Z","shell.execute_reply":"2022-08-07T18:17:50.205709Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"df=pd.read_csv('/kaggle/input/analyticsvidya-jobathon-5-aug-2022/analyticsvidya_jobathon_5_aug_2022_train_F3fUq2S.csv')\ndf_test=pd.read_csv('/kaggle/input/analyticsvidya-jobathon-5-aug-2022/analyticsvidya_jobathon_5_aug_2022_test_Bk2wfZ3.csv')\nsample_sub=pd.read_csv('/kaggle/input/analyticsvidya-jobathon-5-aug-2022/analyticsvidya_jobayhon_5_aug_2022_sample_submission_LJ2N3ZQ.csv')","metadata":{"execution":{"iopub.status.busy":"2022-08-07T18:17:50.339028Z","iopub.execute_input":"2022-08-07T18:17:50.339359Z","iopub.status.idle":"2022-08-07T18:17:50.360622Z","shell.execute_reply.started":"2022-08-07T18:17:50.339318Z","shell.execute_reply":"2022-08-07T18:17:50.359743Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"df.drop(['campaign_id'],axis=1,inplace=True)\ndf_test.drop(['campaign_id'],axis=1,inplace=True)","metadata":{"execution":{"iopub.status.busy":"2022-08-07T18:17:50.519095Z","iopub.execute_input":"2022-08-07T18:17:50.519706Z","iopub.status.idle":"2022-08-07T18:17:50.527300Z","shell.execute_reply.started":"2022-08-07T18:17:50.519676Z","shell.execute_reply":"2022-08-07T18:17:50.526395Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"y=df['click_rate']\nX=df.drop('click_rate',axis=1)","metadata":{"execution":{"iopub.status.busy":"2022-08-07T18:17:50.678930Z","iopub.execute_input":"2022-08-07T18:17:50.679878Z","iopub.status.idle":"2022-08-07T18:17:50.686142Z","shell.execute_reply.started":"2022-08-07T18:17:50.679837Z","shell.execute_reply":"2022-08-07T18:17:50.684854Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"num_cols=['subject_len','body_len','mean_paragraph_len','no_of_CTA','mean_CTA_len','target_audience']\ncat_cols=[c for c in X.columns if c not in num_cols and c not in ['product','times_of_day','day_of_week']]\nactual_cat_cols=['times_of_day','day_of_week']","metadata":{"execution":{"iopub.status.busy":"2022-08-07T18:17:50.969214Z","iopub.execute_input":"2022-08-07T18:17:50.970372Z","iopub.status.idle":"2022-08-07T18:17:50.976762Z","shell.execute_reply.started":"2022-08-07T18:17:50.970302Z","shell.execute_reply":"2022-08-07T18:17:50.975763Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#polynomial  num cols + cat cols\n#Normalizer\n#kfold = 5\n#xgboost best \n#optuna 0.5910286425696581\n\nfrom sklearn.linear_model import LinearRegression,Ridge\nfrom sklearn.metrics import r2_score\nfrom sklearn import preprocessing,model_selection\nfrom xgboost import XGBRegressor\n\ndf_predictions=[]\nmodels=[]\nr2_scores_train=[]\nr2_scores_val=[]\ndf_test_1=df_test.copy()\n\npoly=preprocessing.PolynomialFeatures(1,interaction_only=True)\nX_poly=pd.DataFrame(poly.fit_transform(X[num_cols+cat_cols]))\ndf_test_1_poly=pd.DataFrame(poly.transform(df_test_1[num_cols+cat_cols]))\n\nX_poly=pd.concat([X_poly.reset_index(drop=True),X[actual_cat_cols].reset_index(drop=True)],axis=1)\ndf_test_1_poly=pd.concat([df_test_1_poly.reset_index(drop=True),df_test_1[actual_cat_cols].reset_index(drop=True)],axis=1)\n\nkf=model_selection.KFold(5,shuffle=True,random_state=1)\nfor knum,(train_idx,test_idx) in enumerate(kf.split(X_poly)):\n    X_train,X_val=X_poly.iloc[train_idx],X_poly.iloc[test_idx]\n    y_train,y_val=y[train_idx],y[test_idx]\n    df_test_1=df_test_1_poly.copy()\n    \n    \n    \n   \n    ord_enc=preprocessing.OrdinalEncoder()\n    \n    X_train_ord=pd.DataFrame(ord_enc.fit_transform(X_train[actual_cat_cols]))\n    X_val_ord=pd.DataFrame(ord_enc.transform(X_val[actual_cat_cols]))\n    df_test_1_ord=pd.DataFrame(ord_enc.transform(df_test_1[actual_cat_cols]))\n    \n    X_train_ord.index=X_train.index\n    X_val_ord.index=X_val.index\n    df_test_1_ord.index=df_test_1.index\n    \n    \n    \n    \n    std_scl=preprocessing.Normalizer()\n    X_train_rem=pd.DataFrame(std_scl.fit_transform(X_train.drop(actual_cat_cols,axis=1)))\n    X_val_rem=pd.DataFrame(std_scl.transform(X_val.drop(actual_cat_cols,axis=1)))\n    df_test_1_rem=pd.DataFrame(std_scl.transform(df_test_1.drop(actual_cat_cols,axis=1)))\n    \n    \n    \n    X_train=pd.concat([X_train_rem.reset_index(drop=True),X_train_ord.reset_index(drop=True)],axis=1,ignore_index=True)\n    X_val=pd.concat([X_val_rem.reset_index(drop=True),X_val_ord.reset_index(drop=True)],axis=1,ignore_index=True)\n    df_test_1=pd.concat([df_test_1_rem.reset_index(drop=True),df_test_1_ord.reset_index(drop=True)],axis=1,ignore_index=True)\n    \n\n    \n    new_params={'learning_rate': 0.015119207349205814,\n     'reg_lambda': 1.2652822281260555e-05,\n     'reg_alpha': 1.9346755925423264e-05,\n     'subsample': 0.886572540286282,\n     'colsample_bytree': 0.5999537586785572,\n     'max_depth': 6}\n    model=XGBRegressor(n_jobs=-1,random_state=1\n                        #,gpu_id=0,tree_method='gpu_hist',predictor='gpu_predictor'\n                        ,**new_params\n                      ,early_stopping_rounds=300\n                      ,n_estimators=7000)\n    \n    model.fit(X_train,y_train,eval_set=[(X_val,y_val)],verbose=1000)\n    y_pred=model.predict(X_val)\n    \n    \n    print('R2 Score : Training set = ',r2_score(y_train,model.predict(X_train)),'    Validation set = ',r2_score(y_val,y_pred))\n    \n    df_predictions.append(model.predict(df_test_1))\n    #models.append(model)\n    r2_scores_train.append(r2_score(y_train,model.predict(X_train)))\n    r2_scores_val.append(r2_score(y_val,y_pred))\n    \nprint('Avg r2 score:  Training : ',np.mean(r2_scores_train),'    Validation set = ',np.mean(r2_scores_val))\n\n#predictions=[]\n#for i in range(len(models)):\n#    predictions.append(models[i].predict(X))\n    \n#print('Final r2 score:  Training : ',r2_score(y,np.mean(predictions,axis=0)))\nfinal_prediction1=np.mean(df_predictions,axis=0).tolist()\n","metadata":{"execution":{"iopub.status.busy":"2022-08-07T18:17:51.338992Z","iopub.execute_input":"2022-08-07T18:17:51.339720Z","iopub.status.idle":"2022-08-07T18:18:20.036094Z","shell.execute_reply.started":"2022-08-07T18:17:51.339686Z","shell.execute_reply":"2022-08-07T18:18:20.035244Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"#final_prediction1.tolist()","metadata":{"execution":{"iopub.status.busy":"2022-08-07T18:18:20.040646Z","iopub.execute_input":"2022-08-07T18:18:20.041587Z","iopub.status.idle":"2022-08-07T18:18:20.046950Z","shell.execute_reply.started":"2022-08-07T18:18:20.041541Z","shell.execute_reply":"2022-08-07T18:18:20.045913Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"#polynomial  num cols + cat cols\n#Normalizer\n#kfold = 5\n#xgboost \n# Score =0.5403177047598372 ,fold=5, - Absolute normal only ordinal enc 'time_of_day'\n# Score=0.5805807377193353  ,fold=4, - ohe hot encode cols- actual_cat_cols=['times_of_day','day_of_week']\n# Score=0.58394352213935    ,fold=5  -same as above\n#Score=0.6059578883882286   ,fold=5  -same as above, with optuna\n\n#Score=0.5752140844080066   ,fold=5  - booster : 'dart', rest same as above\n\n\nfrom sklearn.linear_model import LinearRegression,Ridge\nfrom sklearn.metrics import r2_score\nfrom sklearn import preprocessing,model_selection\nfrom xgboost import XGBRegressor\n\ndf_predictions=[]\nmodels=[]\nr2_scores_train=[]\nr2_scores_val=[]\ndf_test_1=df_test.copy()\n\nnum_cols=['subject_len','body_len','mean_paragraph_len','no_of_CTA','mean_CTA_len','target_audience']\ncat_cols=[c for c in X.columns if c not in num_cols and c not in ['product','times_of_day','day_of_week']]\nactual_cat_cols=['times_of_day','day_of_week']\n\n\nkf=model_selection.KFold(5,shuffle=True,random_state=1)\nfor knum,(train_idx,test_idx) in enumerate(kf.split(X_poly)):\n    X_train,X_val=X.iloc[train_idx],X.iloc[test_idx]\n    y_train,y_val=y[train_idx],y[test_idx]\n    df_test_1=df_test.copy()\n    \n    #ord_enc=preprocessing.OrdinalEncoder()\n    #X_train[['times_of_day']]=pd.DataFrame(ord_enc.fit_transform(X_train[['times_of_day']]))\n    #X_val[['times_of_day']]=pd.DataFrame(ord_enc.transform(X_val[['times_of_day']]))\n    #df_test_1[['times_of_day']]=pd.DataFrame(ord_enc.transform(df_test_1[['times_of_day']]))\n    \n    ohe=preprocessing.OneHotEncoder(sparse=False)\n    X_train_ohe=pd.DataFrame(ohe.fit_transform(X_train[actual_cat_cols]))\n    X_val_ohe=pd.DataFrame(ohe.transform(X_val[actual_cat_cols]))\n    df_test_1_ohe=pd.DataFrame(ohe.transform(df_test_1[actual_cat_cols]))\n    \n   \n    #X_train=np.log1p(X_train)\n    #X_val=np.log1p(X_val)\n    #df_test_1=np.log1p(df_test_1)\n    \n    X_train=pd.concat([X_train.drop(actual_cat_cols,axis=1).reset_index(drop=True),X_train_ohe.reset_index(drop=True)],axis=1,ignore_index=True)\n    X_val=pd.concat([X_val.drop(actual_cat_cols,axis=1).reset_index(drop=True),X_val_ohe.reset_index(drop=True)],axis=1,ignore_index=True)\n    df_test_1=pd.concat([df_test_1.drop(actual_cat_cols,axis=1).reset_index(drop=True),df_test_1_ohe.reset_index(drop=True)],axis=1,ignore_index=True)\n    \n\n    #model=LinearRegression()\n    new_params={'learning_rate': 0.03488164266932342,\n     'reg_lambda': 0.14638377598662689,\n     'reg_alpha': 0.002118079241624242,\n     'subsample': 0.8058916328245683,\n     'colsample_bytree': 0.5389818688250179,\n     'max_depth': 7}\n    model=XGBRegressor(n_jobs=-1,random_state=1\n                        #,gpu_id=0,tree_method='gpu_hist',predictor='gpu_predictor'\n                        ,**new_params\n                      ,early_stopping_rounds=300\n                      ,n_estimators=7000\n                      #,enable_categorical=True\n                      )\n    model.fit(X_train,y_train,eval_set=[(X_val,y_val)],verbose=1000)\n    y_pred=model.predict(X_val)\n    \n    \n    print('R2 Score : Training set = ',r2_score(y_train,model.predict(X_train)),'    Validation set = ',r2_score(y_val,y_pred))\n    \n    df_predictions.append(model.predict(df_test_1))\n    models.append(model)\n    r2_scores_train.append(r2_score(y_train,model.predict(X_train)))\n    r2_scores_val.append(r2_score(y_val,y_pred))\n    \nprint('Avg r2 score:  Training : ',np.mean(r2_scores_train),'    Validation set = ',np.mean(r2_scores_val))\n\n#predictions=[]\n#for i in range(len(models)):\n#    predictions.append(models[i].predict(X))\n    \n#print('Final r2 score:  Training : ',r2_score(y,np.mean(predictions,axis=0)))\nfinal_prediction2=np.mean(df_predictions,axis=0).tolist()\n","metadata":{"execution":{"iopub.status.busy":"2022-08-07T18:18:20.048795Z","iopub.execute_input":"2022-08-07T18:18:20.049643Z","iopub.status.idle":"2022-08-07T18:18:36.350769Z","shell.execute_reply.started":"2022-08-07T18:18:20.049607Z","shell.execute_reply":"2022-08-07T18:18:36.349929Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"combine_result=np.mean([final_prediction1,final_prediction2],axis=0)","metadata":{"execution":{"iopub.status.busy":"2022-08-07T18:18:36.354903Z","iopub.execute_input":"2022-08-07T18:18:36.356752Z","iopub.status.idle":"2022-08-07T18:18:36.362359Z","shell.execute_reply.started":"2022-08-07T18:18:36.356718Z","shell.execute_reply":"2022-08-07T18:18:36.361396Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"sample_sub['click_rate']=combine_result.tolist()","metadata":{"execution":{"iopub.status.busy":"2022-08-07T18:18:36.363808Z","iopub.execute_input":"2022-08-07T18:18:36.364204Z","iopub.status.idle":"2022-08-07T18:18:36.374930Z","shell.execute_reply.started":"2022-08-07T18:18:36.364170Z","shell.execute_reply":"2022-08-07T18:18:36.373850Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"sample_sub","metadata":{"execution":{"iopub.status.busy":"2022-08-07T18:18:36.376520Z","iopub.execute_input":"2022-08-07T18:18:36.376893Z","iopub.status.idle":"2022-08-07T18:18:36.395778Z","shell.execute_reply.started":"2022-08-07T18:18:36.376856Z","shell.execute_reply":"2022-08-07T18:18:36.394698Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"sample_sub.to_csv('Jobathon_aug_2022_combine_ordinal_enc_and_One_hot_enc.csv',index=False)","metadata":{"execution":{"iopub.status.busy":"2022-08-07T18:18:36.397756Z","iopub.execute_input":"2022-08-07T18:18:36.398192Z","iopub.status.idle":"2022-08-07T18:18:36.407303Z","shell.execute_reply.started":"2022-08-07T18:18:36.398150Z","shell.execute_reply":"2022-08-07T18:18:36.406309Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}